{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8e1a2f14-3fcd-4da2-b6fc-56321e149f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array, save_img\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "52f34319-6477-4cda-aae8-b0496ab3acb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_path</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>./garbage_classification\\battery\\battery1.jpg</td>\n",
       "      <td>battery</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>./garbage_classification\\battery\\battery10.jpg</td>\n",
       "      <td>battery</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>./garbage_classification\\battery\\battery100.jpg</td>\n",
       "      <td>battery</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>./garbage_classification\\battery\\battery101.jpg</td>\n",
       "      <td>battery</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>./garbage_classification\\battery\\battery102.jpg</td>\n",
       "      <td>battery</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5500</th>\n",
       "      <td>./garbage_classification\\plastic\\plastic95.jpg</td>\n",
       "      <td>plastic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5501</th>\n",
       "      <td>./garbage_classification\\plastic\\plastic96.jpg</td>\n",
       "      <td>plastic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5502</th>\n",
       "      <td>./garbage_classification\\plastic\\plastic97.jpg</td>\n",
       "      <td>plastic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5503</th>\n",
       "      <td>./garbage_classification\\plastic\\plastic98.jpg</td>\n",
       "      <td>plastic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5504</th>\n",
       "      <td>./garbage_classification\\plastic\\plastic99.jpg</td>\n",
       "      <td>plastic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5505 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           image_path    label\n",
       "0       ./garbage_classification\\battery\\battery1.jpg  battery\n",
       "1      ./garbage_classification\\battery\\battery10.jpg  battery\n",
       "2     ./garbage_classification\\battery\\battery100.jpg  battery\n",
       "3     ./garbage_classification\\battery\\battery101.jpg  battery\n",
       "4     ./garbage_classification\\battery\\battery102.jpg  battery\n",
       "...                                               ...      ...\n",
       "5500   ./garbage_classification\\plastic\\plastic95.jpg  plastic\n",
       "5501   ./garbage_classification\\plastic\\plastic96.jpg  plastic\n",
       "5502   ./garbage_classification\\plastic\\plastic97.jpg  plastic\n",
       "5503   ./garbage_classification\\plastic\\plastic98.jpg  plastic\n",
       "5504   ./garbage_classification\\plastic\\plastic99.jpg  plastic\n",
       "\n",
       "[5505 rows x 2 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Путь до основного каталога\n",
    "base_dir = './garbage_classification'\n",
    "\n",
    "# Составление массива классов из папок\n",
    "garbage_types = ['battery', 'biological', 'cardboard', 'metal', 'paper', 'plastic']\n",
    "\n",
    "# сбор путей к изображениям и меткам\n",
    "image_paths = []\n",
    "image_labels =[]\n",
    "\n",
    "for garbageType in garbage_types:\n",
    "    garbage_dir = os.path.join(base_dir, garbageType) # ./garbage_classification/battery\n",
    "    for namePhoto in os.listdir(garbage_dir):\n",
    "        image_paths.append(os.path.join(garbage_dir, namePhoto))\n",
    "        image_labels.append(garbageType)\n",
    "\n",
    "# Создаем DataFrame: image_paths, image_labels\n",
    "df = pd.DataFrame({\n",
    "    'image_path': image_paths,\n",
    "    'label': image_labels\n",
    "})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6a701572-aff2-4197-8de9-4a0328609aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разделяем данные на тренировочную и тестовую выборки в соотношении 70 на 30 процентов для тренировочной и  тестовой соответственно\n",
    "train_df, test_df = train_test_split(df, test_size=0.3, random_state=23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b82ffa2-f4b1-468e-b7c4-47721f7494d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Аугментация данных\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    rotation_range=45,\n",
    "    vertical_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "703c8cfa-b6b9-4238-a7e3-a412e0aaa163",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3853 validated image filenames belonging to 6 classes.\n",
      "Found 1652 validated image filenames belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "# Создаем генераторы\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    dataframe = train_df,\n",
    "    x_col = 'image_path',\n",
    "    y_col='label',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_dataframe(\n",
    "    dataframe = test_df,\n",
    "    x_col = 'image_path',\n",
    "    y_col = 'label',\n",
    "    target_size = (224, 224),\n",
    "    batch_size = 32,\n",
    "    class_mode = 'categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd4d3b05-6955-4696-a2b9-de7dc544e8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Содание модели\n",
    "def create_model():\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), input_shape=(224, 224, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(2, 2))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(2, 2))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(2, 2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(6, activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "83ce8651-e5a6-45bb-8ba5-dc8130efd426",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Обучение с оптимизатором adam.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kseny\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "C:\\Users\\kseny\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 1s/step - accuracy: 0.2988 - loss: 2.0380 - val_accuracy: 0.5339 - val_loss: 1.1975\n",
      "Epoch 2/10\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 995ms/step - accuracy: 0.5381 - loss: 1.2587 - val_accuracy: 0.5823 - val_loss: 1.1257\n",
      "Epoch 3/10\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 1s/step - accuracy: 0.5857 - loss: 1.1419 - val_accuracy: 0.6090 - val_loss: 1.0363\n",
      "Epoch 4/10\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 1s/step - accuracy: 0.6004 - loss: 1.0890 - val_accuracy: 0.6410 - val_loss: 0.9776\n",
      "Epoch 5/10\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 1s/step - accuracy: 0.6238 - loss: 1.0243 - val_accuracy: 0.6507 - val_loss: 0.9890\n",
      "Epoch 6/10\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 1s/step - accuracy: 0.6600 - loss: 0.9548 - val_accuracy: 0.6719 - val_loss: 0.9139\n",
      "Epoch 7/10\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 1s/step - accuracy: 0.6325 - loss: 1.0081 - val_accuracy: 0.6937 - val_loss: 0.8663\n",
      "Epoch 8/10\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 1s/step - accuracy: 0.6556 - loss: 0.9423 - val_accuracy: 0.6973 - val_loss: 0.8597\n",
      "Epoch 9/10\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 1s/step - accuracy: 0.6829 - loss: 0.8968 - val_accuracy: 0.6955 - val_loss: 0.8074\n",
      "Epoch 10/10\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 1s/step - accuracy: 0.6814 - loss: 0.8572 - val_accuracy: 0.7100 - val_loss: 0.8442\n",
      "adam: Final accuracy = 0.7100\n",
      "Обучение с оптимизатором adamw.\n",
      "Epoch 1/10\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 1s/step - accuracy: 0.2998 - loss: 1.9877 - val_accuracy: 0.5200 - val_loss: 1.2267\n",
      "Epoch 2/10\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 1s/step - accuracy: 0.5684 - loss: 1.1936 - val_accuracy: 0.5684 - val_loss: 1.1835\n",
      "Epoch 3/10\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 1s/step - accuracy: 0.5661 - loss: 1.1558 - val_accuracy: 0.6247 - val_loss: 1.0002\n",
      "Epoch 4/10\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 1s/step - accuracy: 0.6088 - loss: 1.0815 - val_accuracy: 0.6416 - val_loss: 0.9642\n",
      "Epoch 5/10\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 1s/step - accuracy: 0.6372 - loss: 1.0081 - val_accuracy: 0.6404 - val_loss: 0.9594\n",
      "Epoch 6/10\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 1s/step - accuracy: 0.6431 - loss: 0.9887 - val_accuracy: 0.6483 - val_loss: 1.0014\n",
      "Epoch 7/10\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 1s/step - accuracy: 0.6459 - loss: 0.9671 - val_accuracy: 0.6889 - val_loss: 0.8695\n",
      "Epoch 8/10\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 1s/step - accuracy: 0.6539 - loss: 0.9571 - val_accuracy: 0.6749 - val_loss: 0.9118\n",
      "Epoch 9/10\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 1s/step - accuracy: 0.6965 - loss: 0.8697 - val_accuracy: 0.6816 - val_loss: 0.8884\n",
      "Epoch 10/10\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 1s/step - accuracy: 0.6814 - loss: 0.8680 - val_accuracy: 0.6762 - val_loss: 0.8981\n",
      "adamw: Final accuracy = 0.6762\n",
      "Обучение с оптимизатором sgd.\n",
      "Epoch 1/10\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 914ms/step - accuracy: 0.2289 - loss: 1.7497 - val_accuracy: 0.3487 - val_loss: 1.5164\n",
      "Epoch 2/10\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 903ms/step - accuracy: 0.3689 - loss: 1.5416 - val_accuracy: 0.3608 - val_loss: 1.5247\n",
      "Epoch 3/10\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 902ms/step - accuracy: 0.4366 - loss: 1.4467 - val_accuracy: 0.5617 - val_loss: 1.2149\n",
      "Epoch 4/10\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 908ms/step - accuracy: 0.4901 - loss: 1.3307 - val_accuracy: 0.5351 - val_loss: 1.1848\n",
      "Epoch 5/10\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 910ms/step - accuracy: 0.5332 - loss: 1.2482 - val_accuracy: 0.5690 - val_loss: 1.1588\n",
      "Epoch 6/10\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 906ms/step - accuracy: 0.5496 - loss: 1.2061 - val_accuracy: 0.5981 - val_loss: 1.0762\n",
      "Epoch 7/10\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 903ms/step - accuracy: 0.5688 - loss: 1.1710 - val_accuracy: 0.5781 - val_loss: 1.0629\n",
      "Epoch 8/10\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 907ms/step - accuracy: 0.5882 - loss: 1.1471 - val_accuracy: 0.6017 - val_loss: 1.0540\n",
      "Epoch 9/10\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 898ms/step - accuracy: 0.6029 - loss: 1.1006 - val_accuracy: 0.6423 - val_loss: 0.9628\n",
      "Epoch 10/10\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 906ms/step - accuracy: 0.6058 - loss: 1.0721 - val_accuracy: 0.5097 - val_loss: 1.2269\n",
      "sgd: Final accuracy = 0.5097\n",
      "\n",
      "Results\n",
      "adam: 0.7100\n",
      "adamw: 0.6762\n",
      "sgd: 0.5097\n"
     ]
    }
   ],
   "source": [
    "optimizers = {\n",
    "    'adam': 'adam',\n",
    "    'adamw': 'adamw',\n",
    "    'sgd': 'sgd'\n",
    "}\n",
    "\n",
    "final_accuracies = {}\n",
    "\n",
    "for opt_name, opt in optimizers.items():\n",
    "    print(f\"Обучение с оптимизатором {opt_name}.\")\n",
    "    model = create_model()\n",
    "    model.compile(optimizer = opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    history = model.fit(\n",
    "        train_generator,\n",
    "        epochs = 10,\n",
    "        validation_data=test_generator,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    final_accuracy = history.history['val_accuracy'][-1]\n",
    "    final_accuracies[opt_name] = final_accuracy\n",
    "    print(f\"{opt_name}: Final accuracy = {final_accuracy:.4f}\")\n",
    "\n",
    "print(\"\\nResults\")\n",
    "for opt_name, accuracy in final_accuracies.items():\n",
    "    print(f\"{opt_name}: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c1df0096-7cf1-4743-b022-bd213801a270",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3853 validated image filenames belonging to 6 classes.\n",
      "Found 1652 validated image filenames belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "new_train_generator = train_datagen.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    x_col='image_path',\n",
    "    y_col='label',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=64,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "new_test_generator = test_datagen.flow_from_dataframe(\n",
    "    dataframe=test_df,\n",
    "    x_col='image_path',\n",
    "    y_col='label',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=64,\n",
    "    class_mode='categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "20508a66-c2dc-474e-92e6-0194850451a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Обучение с оптимизатором adam.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kseny\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "C:\\Users\\kseny\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 2s/step - accuracy: 0.3262 - loss: 2.0039 - val_accuracy: 0.5860 - val_loss: 1.1374\n",
      "Epoch 2/15\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 2s/step - accuracy: 0.5641 - loss: 1.1894 - val_accuracy: 0.6162 - val_loss: 1.0875\n",
      "Epoch 3/15\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 2s/step - accuracy: 0.5950 - loss: 1.1448 - val_accuracy: 0.6192 - val_loss: 1.0431\n",
      "Epoch 4/15\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 2s/step - accuracy: 0.6453 - loss: 1.0197 - val_accuracy: 0.6755 - val_loss: 0.9066\n",
      "Epoch 5/15\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 2s/step - accuracy: 0.6621 - loss: 0.9513 - val_accuracy: 0.6961 - val_loss: 0.8436\n",
      "Epoch 6/15\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 2s/step - accuracy: 0.6854 - loss: 0.9068 - val_accuracy: 0.6574 - val_loss: 0.9515\n",
      "Epoch 7/15\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 2s/step - accuracy: 0.6747 - loss: 0.8918 - val_accuracy: 0.7185 - val_loss: 0.8106\n",
      "Epoch 8/15\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 2s/step - accuracy: 0.6883 - loss: 0.8655 - val_accuracy: 0.6574 - val_loss: 1.0458\n",
      "Epoch 9/15\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 2s/step - accuracy: 0.6881 - loss: 0.8663 - val_accuracy: 0.6901 - val_loss: 0.8872\n",
      "Epoch 10/15\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 2s/step - accuracy: 0.7090 - loss: 0.8290 - val_accuracy: 0.7088 - val_loss: 0.8003\n",
      "Epoch 11/15\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 2s/step - accuracy: 0.7193 - loss: 0.7816 - val_accuracy: 0.7113 - val_loss: 0.8191\n",
      "Epoch 12/15\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 2s/step - accuracy: 0.7252 - loss: 0.7589 - val_accuracy: 0.7476 - val_loss: 0.7141\n",
      "Epoch 13/15\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 2s/step - accuracy: 0.7566 - loss: 0.7302 - val_accuracy: 0.7306 - val_loss: 0.7681\n",
      "Epoch 14/15\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 2s/step - accuracy: 0.7337 - loss: 0.7542 - val_accuracy: 0.7452 - val_loss: 0.7891\n",
      "Epoch 15/15\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 2s/step - accuracy: 0.7318 - loss: 0.7292 - val_accuracy: 0.7657 - val_loss: 0.7018\n",
      "adam: Final accuracy = 0.7657\n",
      "Обучение с оптимизатором adamw.\n",
      "Epoch 1/15\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 2s/step - accuracy: 0.2880 - loss: 2.6377 - val_accuracy: 0.5145 - val_loss: 1.2305\n",
      "Epoch 2/15\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 2s/step - accuracy: 0.5435 - loss: 1.2462 - val_accuracy: 0.6126 - val_loss: 1.0471\n",
      "Epoch 3/15\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 2s/step - accuracy: 0.6085 - loss: 1.0866 - val_accuracy: 0.6295 - val_loss: 0.9798\n",
      "Epoch 4/15\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 2s/step - accuracy: 0.6267 - loss: 1.0197 - val_accuracy: 0.6386 - val_loss: 0.9640\n",
      "Epoch 5/15\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 2s/step - accuracy: 0.6404 - loss: 0.9834 - val_accuracy: 0.6489 - val_loss: 0.9550\n",
      "Epoch 6/15\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 2s/step - accuracy: 0.6678 - loss: 0.9370 - val_accuracy: 0.6701 - val_loss: 0.8592\n",
      "Epoch 7/15\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 2s/step - accuracy: 0.6767 - loss: 0.8758 - val_accuracy: 0.6792 - val_loss: 0.8622\n",
      "Epoch 8/15\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 2s/step - accuracy: 0.6941 - loss: 0.8578 - val_accuracy: 0.6544 - val_loss: 0.8990\n",
      "Epoch 9/15\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 2s/step - accuracy: 0.6954 - loss: 0.8367 - val_accuracy: 0.6992 - val_loss: 0.8116\n",
      "Epoch 10/15\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 2s/step - accuracy: 0.6910 - loss: 0.8458 - val_accuracy: 0.7324 - val_loss: 0.7440\n",
      "Epoch 11/15\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 2s/step - accuracy: 0.7189 - loss: 0.7601 - val_accuracy: 0.7167 - val_loss: 0.7977\n",
      "Epoch 12/15\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 2s/step - accuracy: 0.7236 - loss: 0.7613 - val_accuracy: 0.7397 - val_loss: 0.7297\n",
      "Epoch 13/15\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 2s/step - accuracy: 0.7321 - loss: 0.7448 - val_accuracy: 0.7240 - val_loss: 0.7482\n",
      "Epoch 14/15\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 2s/step - accuracy: 0.7149 - loss: 0.7681 - val_accuracy: 0.7137 - val_loss: 0.8130\n",
      "Epoch 15/15\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 2s/step - accuracy: 0.7508 - loss: 0.7127 - val_accuracy: 0.7427 - val_loss: 0.7158\n",
      "adamw: Final accuracy = 0.7427\n",
      "\n",
      "Results\n",
      "adam: 0.7657\n",
      "adamw: 0.7427\n"
     ]
    }
   ],
   "source": [
    "optimizers = {\n",
    "    'adam': 'adam',\n",
    "    'adamw': 'adamw',\n",
    "}\n",
    "\n",
    "final_accuracies = {}\n",
    "\n",
    "for opt_name, opt in optimizers.items():\n",
    "    print(f\"Обучение с оптимизатором {opt_name}.\")\n",
    "    model = create_model()\n",
    "    model.compile(optimizer = opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    history = model.fit(\n",
    "        new_train_generator,\n",
    "        epochs = 15,\n",
    "        validation_data=new_test_generator,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    final_accuracy = history.history['val_accuracy'][-1]\n",
    "    final_accuracies[opt_name] = final_accuracy\n",
    "    print(f\"{opt_name}: Final accuracy = {final_accuracy:.4f}\")\n",
    "\n",
    "print(\"\\nResults\")\n",
    "for opt_name, accuracy in final_accuracies.items():\n",
    "    print(f\"{opt_name}: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa0ab58-d83c-4c18-94d9-1df70b659814",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
